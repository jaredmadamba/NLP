{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An app to take English user input and return Japanese, Romanized Japanese, and a sentiment analysis of the translated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "# pip install -U pip setuptools wheel\n",
    "# pip install -U spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "# python -m spacy download ja_core_news_sm\n",
    "\n",
    "# pip install --user asari\n",
    "\n",
    "# python -m unidic download\n",
    "# pip install mecab-python3\n",
    "# pip install cutlet\n",
    "\n",
    "# pip install sacrebleu\n",
    "\n",
    "# pip install --user ipywidgets\n",
    "# pip install --user gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizing and Analysis Dependencies\n",
    "# English and Japanese Spacy Pipelines\n",
    "\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "en_parse = spacy.load(\"en_core_web_sm\")\n",
    "jp_parse = spacy.load(\"ja_core_news_sm\")\n",
    "\n",
    "# Translation Dependencies\n",
    "from translate import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x1dc38565760>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up pipeline for English sentiment analysis\n",
    "en_parse.add_pipe(\"spacytextblob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15272108843537419"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Polarity of original Text.\n",
    "import pprint as pp\n",
    "text = \"You used to like working with us mercs a whole bunch. Mercenaries are efficient instruments of war. Just like fast food, ready to eat and easily disposable. You want to know what happened in the past? Hmm, some people would prefer I keep my mouth shut about that topic. Say, it must be such a blessing to not remember anything, right?\"\n",
    "sent = en_parse(text)\n",
    "sent._.blob.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You used to like working with us mercs a whole bunch.\n",
      "Mercenaries are efficient instruments of war.\n",
      "Just like fast food, ready to eat and easily disposable.\n",
      "You want to know what happened in the past?\n",
      "Hmm, some people would prefer I keep my mouth shut about that topic.\n",
      "Say, it must be such a blessing to not remember anything, right?\n"
     ]
    }
   ],
   "source": [
    "for token in sent.sents:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation Pipeline\n",
    "translator= Translator(to_lang=\"ja\")\n",
    "\n",
    "# Empty list to store the translated tokens\n",
    "tl = []\n",
    "\n",
    "for token in sent.sents:\n",
    "    translation = translator.translate(token.text)\n",
    "    tl.append(translation)\n",
    "\n",
    "# Recombine tokens as a single string.\n",
    "tl_string = \"\".join(tl) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/polm/cutlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "傭兵たちと一緒に働くのが好きだったな。傭兵は効率的な戦争の道具です。ファストフードと同じように、すぐに食べられ、使い捨ても簡単です。過去に何があったのか知りたいですか？うーん、その話題については口を閉ざしておいたほうがいいと思う人もいます。ねえ、何も覚えていないのは恵みですよね？\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Youheitachi to issho ni hataraku no ga suki datta na. youhei wa kouritsuteki na sensou no dougu desu. fasuto fuudo to onaji you ni, sugu ni taberare, tsukaisute mo kantan desu. kako ni nan ga atta no ka shiritai desu ka? uun, sono wadai ni tsuite wa kuchi wo tozashite oita hou ga ii to omou hito mo imasu. nee, nan mo oboete inai no wa megumi desu yo ne?'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Romanizes the JP Kana/Kanji\n",
    "import cutlet\n",
    "\n",
    "romanizer = cutlet.Cutlet()\n",
    "romanizer.use_foreign_spelling = False\n",
    "\n",
    "print(tl_string)\n",
    "romanizer.romaji(tl_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "傭兵たちと一緒に働くのが好きだったな。\n",
      "Youheitachi to issho ni hataraku no ga suki datta na.\n",
      "傭兵は効率的な戦争の道具です。\n",
      "Youhei wa kouritsuteki na sensou no dougu desu.\n",
      "ファストフードと同じように、すぐに食べられ、使い捨ても簡単です。\n",
      "Fasuto fuudo to onaji you ni, sugu ni taberare, tsukaisute mo kantan desu.\n",
      "過去に何があったのか知りたいですか？うーん、その話題については口を閉ざしておいたほうがいいと思う人もいます。\n",
      "Kako ni nan ga atta no ka shiritai desu ka? uun, sono wadai ni tsuite wa kuchi wo tozashite oita hou ga ii to omou hito mo imasu.\n",
      "ねえ、何も覚えていないのは恵みですよね？\n",
      "Nee, nan mo oboete inai no wa megumi desu yo ne?\n"
     ]
    }
   ],
   "source": [
    "# Stores the tokenized translated text.\n",
    "\n",
    "token_jp = jp_parse(tl_string)\n",
    "\n",
    "test = []\n",
    "\n",
    "for token in token_jp.sents:\n",
    "    test.append(token.text)\n",
    "    print(token.text)\n",
    "    print(romanizer.romaji(token.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/mjpost/sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "あたしたちは昔のあんたといいお付き合いをさせてもらってたわ。\n",
      "Atashitachi wa mukashi no anta to ii otsukiai wo sasete moratteta wa.\n",
      "だって傭兵は効率の良い戦争道具だもの。\n",
      "Da tte youhei wa kouritsu no yoi sensou dougu da mono.\n",
      "ファーストフードみたいに食べたい時に食べて、要らなくなったら捨てるだけ。\n",
      "Faasuto fuudo mitai ni tabetai toki ni tabete, iranaku nattara suteru dake.\n",
      "過去に何があったかって？あら、あたしが喋りすぎるのを嫌う人もいるのよ。\n",
      "Kako ni nan ga atta ka tte? ara, atashi ga shaberi sugiru no wo kirau hito mo iru no yo.\n",
      "でも何も覚えてないのは幸せなこと、そうでしょ？\n",
      "De mo nan mo oboetenai no wa shiawase na koto, sou desho?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BLEU = 0.00 0.0/0.0/0.0/0.0 (BP = 1.000 ratio = 1.000 hyp_len = 5 ref_len = 5)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLEU Scoring against the official, localized Japanese translation.\n",
    "# However, this library does not seem to handle Japanese properly, given JP and Korean are the few that it requires a separate library instead of its own.\n",
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "reference_sentence = \"あたしたちは昔のあんたといいお付き合いをさせてもらってたわ。だって傭兵は効率の良い戦争道具だもの。ファーストフードみたいに食べたい時に食べて、要らなくなったら捨てるだけ。過去に何があったかって？あら、あたしが喋りすぎるのを嫌う人もいるのよ。でも何も覚えてないのは幸せなこと、そうでしょ？\"\n",
    "\n",
    "ref = []\n",
    "\n",
    "token_eval = jp_parse(reference_sentence)\n",
    "for token in token_eval.sents:\n",
    "    ref.append(token.text)\n",
    "    print(token.text)\n",
    "    print(romanizer.romaji(token.text))\n",
    "\n",
    "bleu = BLEU()\n",
    "\n",
    "bleu.corpus_score(test, ref)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Hironsan/asari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': [{'class_name': 'negative', 'confidence': 0.05036956071853638},\n",
      "             {'class_name': 'positive', 'confidence': 0.9496304392814636}],\n",
      " 'text': '傭兵たちと一緒に働くのが好きだったな。傭兵は効率的な戦争の道具です。ファストフードと同じように、すぐに食べられ、使い捨ても簡単です。過去に何があったのか知りたいですか？うーん、その話題については口を閉ざしておいたほうがいいと思う人もいます。ねえ、何も覚えていないのは恵みですよね？',\n",
      " 'top_class': 'positive'}\n"
     ]
    }
   ],
   "source": [
    "# Setting up Japanese Sentiment Analysis\n",
    "from asari.api import Sonar\n",
    "sonar = Sonar()\n",
    "jp_sent = sonar.ping(text=tl_string)\n",
    "pp.pprint(jp_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive, {0.9496304392814636}\n"
     ]
    }
   ],
   "source": [
    "#  Deriving the rating and confidence rate from the sentiment analysis dictionary.\n",
    "rating = {i['confidence'] for i in jp_sent['classes'] if i['class_name'] ==jp_sent [\"top_class\"]}\n",
    "print(\"{}, {}\".format(jp_sent[\"top_class\"], rating))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Implementation of Above for Interface. Ensure Spacey, TextBlob, Cutlet, and Asari have been initialized to run properly.\n",
    "def full_translate(user_text):\n",
    "\n",
    "    if user_text == \"\" or user_text.isspace():\n",
    "        return(\"\",\"\",\"\")\n",
    "\n",
    "    en_tokenized = en_parse(user_text)\n",
    "    \n",
    "    tl_tokenized = []\n",
    "\n",
    "    for token in en_tokenized.sents:\n",
    "        translation = translator.translate(token.text)\n",
    "        tl_tokenized.append(translation)\n",
    "\n",
    "    oneline = \"\".join(tl_tokenized)\n",
    "\n",
    "    sentiment = sonar.ping(text=oneline)\n",
    "    rating = {i['confidence'] for i in sentiment['classes'] if i['class_name'] ==sentiment [\"top_class\"]}\n",
    "    sent_output = \"{}, {}\".format(sentiment[\"top_class\"], rating)\n",
    "\n",
    "    return(oneline, romanizer.romaji(oneline), sent_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UI: https://www.gradio.app/docs/interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "interface = gr.Interface(fn=full_translate, inputs=gr.Textbox(lines=5, placeholder='Text to translate'), outputs=['text','text','text'], theme='monochrome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7874\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
